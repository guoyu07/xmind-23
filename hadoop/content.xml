<?xml version="1.0" encoding="UTF-8" standalone="no"?><xmap-content xmlns="urn:xmind:xmap:xmlns:content:2.0" xmlns:fo="http://www.w3.org/1999/XSL/Format" xmlns:svg="http://www.w3.org/2000/svg" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:xlink="http://www.w3.org/1999/xlink" timestamp="1394441367113" version="2.0"><sheet id="7thjki05dfe85no4qefjl6d53d" timestamp="1394441367113"><topic id="1845jb1d81p4mgj9fliu21d9d7" structure-class="org.xmind.ui.map.clockwise" timestamp="1394439143423"><title>Hadoop</title><children><topics type="attached"><topic id="0fafhbmhl49mn9f0d1abgcs31j" timestamp="1394441367113"><title>5、MapReduce</title><children><topics type="attached"><topic id="0kf0ibpgtc3qkdui4f3i9fbpbr" timestamp="1394175802042"><title>1、业界相关</title><children><topics type="attached"><topic id="4tp6c63rf8ep8oq26vmvk1afrp" timestamp="1394173374933"><title>1、并行计算框架</title><notes><html><xhtml:p>1、MPI</xhtml:p><xhtml:p>2、PVM</xhtml:p><xhtml:p>3、CUDA		http://cuda.it168.com/</xhtml:p><xhtml:p>4、BOINC		http://boinc.berkeley.edu/</xhtml:p><xhtml:p>5、Map-Reduce</xhtml:p><xhtml:p/></html><plain>1、MPI
2、PVM
3、CUDA		http://cuda.it168.com/
4、BOINC		http://boinc.berkeley.edu/
5、Map-Reduce
</plain></notes></topic><topic id="06uoi8b5ltcqo39tlqv63tbf48" timestamp="1394173675935"><title>2、云计算是什么</title><notes><html><xhtml:p/><xhtml:p><xhtml:img xhtml:src="xap:attachments/6637ia61h8idntcnfkcmulhd2u.png"/></xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/07dbmonrob2dfjrs9fgbiauiur.png"/></xhtml:p></html><plain>

</plain></notes></topic><topic id="3ovommfcf2b6ufs4vgpfq4nd4i" timestamp="1394174055320"><title>3、云计算特征</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/7ij3ijr6ticvk17t0qnpuggg3u.png"/></xhtml:p></html><plain/></notes></topic><topic id="76clbhqo0nauiuscdm8egcnuae" timestamp="1394174278331"><title>4、怎样降低成本</title><notes><html><xhtml:p>1、提高软硬件使用率</xhtml:p><xhtml:p>2、集中管理降低能耗</xhtml:p><xhtml:p>3、节约维护人员费用</xhtml:p><xhtml:p/></html><plain>1、提高软硬件使用率
2、集中管理降低能耗
3、节约维护人员费用
</plain></notes></topic><topic id="3696k4p7i75v0eol3gelnpftec" timestamp="1394174357241"><title>5、风险</title><notes><html><xhtml:p>1、安全风险</xhtml:p><xhtml:p>2、可用性风险</xhtml:p><xhtml:p>3、绑架风险</xhtml:p><xhtml:p/></html><plain>1、安全风险
2、可用性风险
3、绑架风险
</plain></notes></topic><topic id="6mbhir3g2afke3tsi8u4kestth" timestamp="1394175548117"><title>6、开源云计算解决方案</title><notes><html><xhtml:p>1、Hadoop</xhtml:p><xhtml:p>	a、分布式文件系统提供的低单位成本的巨大的存储能力，高冗余的可靠性</xhtml:p><xhtml:p>	b、Map-Reduce提供快速并行计算能力，这种能力可以随着节点数的增加线性递增</xhtml:p><xhtml:p>2、Openstack</xhtml:p><xhtml:p>	虚拟集群的管理</xhtml:p><xhtml:p/></html><plain>1、Hadoop
	a、分布式文件系统提供的低单位成本的巨大的存储能力，高冗余的可靠性
	b、Map-Reduce提供快速并行计算能力，这种能力可以随着节点数的增加线性递增
2、Openstack
	虚拟集群的管理
</plain></notes></topic><topic id="2acknnemu6cq6jgad84f1cbhg5" timestamp="1394175812845"><title>7、案例</title><children><topics type="attached"><topic id="5bjanuqjqng77b3g6ekn6u03es" timestamp="1394175808505"><title>1、taobao</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/0oqnksurot3o1726p0lhi8d9up.png"/></xhtml:p></html><plain/></notes></topic><topic id="45cne55ibf0c2ca174qkm3i15n" timestamp="1394175835553"><title>2、baidu</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/2dkh2t050ogka4sb71fnd110ns.png"/></xhtml:p></html><plain/></notes></topic></topics></children></topic></topics></children></topic></topics></children><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/3fjvqocvguifu91aaog923t6cr.png"/><xhtml:span style-id="7turfdg0su2teous0bsv0h1b05"/></xhtml:p><xhtml:p/><xhtml:p><xhtml:img xhtml:src="xap:attachments/23qk9842c64a2thobnbvignh4g.png"/></xhtml:p></html><plain>

</plain></notes></topic><topic id="1j8250b7nf094mj9lq1b9k3nik" timestamp="1394439156766"><title>6、HBase</title></topic><topic branch="folded" id="5tcjp876nq7teedck0rcjoho1f" timestamp="1394169692089"><title>4、HDFS</title><notes><html><xhtml:p>提供分布式存储机制，提供可线性增长的海量存储能力</xhtml:p><xhtml:p>自动数据冗余，无须使用raid，无须另行备份</xhtml:p><xhtml:p>为进一步分析计算提供数据基础</xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/0i2iv9mpse7nd8aagit6slib6d.png"/></xhtml:p></html><plain>提供分布式存储机制，提供可线性增长的海量存储能力
自动数据冗余，无须使用raid，无须另行备份
为进一步分析计算提供数据基础
</plain></notes><children><topics type="attached"><topic id="6qcb8mr8o23cfh867d12vovrth" timestamp="1394160024673"><title>hdfs设计基础和目标</title><notes><html><xhtml:p>1、硬件错误是常态，因此需要<xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">冗余</xhtml:span></xhtml:p><xhtml:p>2、流式数据访问。即数据<xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">批量读取而非随机读写</xhtml:span>，Hadoop擅长做的是数据分析而不是事务处理</xhtml:p><xhtml:p>3、<xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">大规模</xhtml:span>数据集</xhtml:p><xhtml:p>4、简单一致性模型。为了降低系统复杂度，对文件采用一次性写多次度的逻辑设计，即是文件一经写入，关闭，就再也<xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">不能修改</xhtml:span></xhtml:p><xhtml:p>5、程序采用“数据就近”原则分配节点执行</xhtml:p><xhtml:p/></html><plain>1、硬件错误是常态，因此需要冗余
2、流式数据访问。即数据批量读取而非随机读写，Hadoop擅长做的是数据分析而不是事务处理
3、大规模数据集
4、简单一致性模型。为了降低系统复杂度，对文件采用一次性写多次度的逻辑设计，即是文件一经写入，关闭，就再也不能修改
5、程序采用“数据就近”原则分配节点执行
</plain></notes></topic><topic id="5qb1c7ljrirkqmd1bqij7ku21n" timestamp="1394161496568"><title>hdfs体系结构</title><notes><html><xhtml:p>NameNode</xhtml:p><xhtml:p>DataNode</xhtml:p><xhtml:p>事务日志</xhtml:p><xhtml:p>映像文件</xhtml:p><xhtml:p>SecondaryNameNode</xhtml:p><xhtml:p/></html><plain>NameNode
DataNode
事务日志
映像文件
SecondaryNameNode
</plain></notes><children><topics type="attached"><topic id="5go5jjmb6madnqtpp96s45kk98" timestamp="1394160963080"><title>NameNode</title><notes><html><xhtml:p>1、管理文件系统的命名空间</xhtml:p><xhtml:p>2、记录每个文件数据块在各个datanode上的位置和副本信息</xhtml:p><xhtml:p>3、协调客户端对文件的访问</xhtml:p><xhtml:p>4、记录命名空间内的改动或空间本身属性的改动</xhtml:p><xhtml:p>5、</xhtml:p></html><plain>1、管理文件系统的命名空间
2、记录每个文件数据块在各个datanode上的位置和副本信息
3、协调客户端对文件的访问
4、记录命名空间内的改动或空间本身属性的改动
5、</plain></notes></topic><topic id="0tumokjrfhfmgpuojr2eos8md1" timestamp="1394161047475"><title>DataNode</title><notes><html><xhtml:p>1、负责所在物理节点的存储管理</xhtml:p><xhtml:p>2、一次写入，多次读取（不修改）</xhtml:p><xhtml:p>3、文件由数据块组成，典型的块大小的64M</xhtml:p><xhtml:p>4、数据块尽量散布到各个节点</xhtml:p><xhtml:p/></html><plain>1、负责所在物理节点的存储管理
2、一次写入，多次读取（不修改）
3、文件由数据块组成，典型的块大小的64M
4、数据块尽量散布到各个节点
</plain></notes></topic><topic id="19i2o21c8bdfgorrlbgrdl2gio" timestamp="1394163507341"><title>HDFS可靠性</title><notes><html><xhtml:p>1、冗余副本策略</xhtml:p><xhtml:p>2、机架策略</xhtml:p><xhtml:p>3、心跳机制</xhtml:p><xhtml:p>4、安全模式</xhtml:p><xhtml:p>5、校验和</xhtml:p><xhtml:p>6、回收站</xhtml:p><xhtml:p>7、元数据保护</xhtml:p><xhtml:p>8、快照机制</xhtml:p><xhtml:p/></html><plain>1、冗余副本策略
2、机架策略
3、心跳机制
4、安全模式
5、校验和
6、回收站
7、元数据保护
8、快照机制
</plain></notes><children><topics type="attached"><topic id="38erjeqnt660u2jjpejt0d5ptp" timestamp="1394162214886"><title>1、冗余副本策略</title><notes><html><xhtml:p>1、可以在hdfs-site.xml中设置复制因子指定副本数量</xhtml:p><xhtml:p>2、所有数据块都有副本</xhtml:p><xhtml:p>3、datanode启动时，遍历本地文件系统，产生一份hdfs数据块和本地文件的对应关系列表（blockreport）汇报给namenode</xhtml:p><xhtml:p/></html><plain>1、可以在hdfs-site.xml中设置复制因子指定副本数量
2、所有数据块都有副本
3、datanode启动时，遍历本地文件系统，产生一份hdfs数据块和本地文件的对应关系列表（blockreport）汇报给namenode
</plain></notes></topic><topic id="2k1dlr1j3g4lt8qtvtpo0lfcml" timestamp="1394162263928"><title>2、机架策略</title><notes><html><xhtml:p>1、集群一般放在不同机架上，机架间带宽要比机架内带宽要小</xhtml:p><xhtml:p>2、hdfs的“机架感知”</xhtml:p><xhtml:p>3、一般在本机架存放一个副本，在其他机架再存放别的副本，这样可以防止机架失效时丢失数据，也可以提供带宽利用率</xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/1qtr1bmuappehb97bunf0f96kn.png"/></xhtml:p></html><plain>1、集群一般放在不同机架上，机架间带宽要比机架内带宽要小
2、hdfs的“机架感知”
3、一般在本机架存放一个副本，在其他机架再存放别的副本，这样可以防止机架失效时丢失数据，也可以提供带宽利用率
</plain></notes></topic><topic id="0rj05gdenbi64vbmfhlsmiqv2i" timestamp="1394162516445"><title>3、心跳机制</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/4jhsgsc1jn16d4kv5jb2r9l8jr.png"/></xhtml:p></html><plain/></notes></topic><topic id="1g3g66333tt9uagt4018jt4oki" timestamp="1394163126720"><title>4、安全模式</title><notes><html><xhtml:p>1、NameNode启动时会先经过一个“安全模式”阶段</xhtml:p><xhtml:p>2、安全模式阶段不会产生数据写入</xhtml:p><xhtml:p>3、在此阶段NameNode手机各个DataNode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的</xhtml:p><xhtml:p>4、在一定比例（可设置）的数据块被确定为“安全”后，在过若干时间，安全模式结束</xhtml:p><xhtml:p>5、当检测到副本数不足的数据块时，该块会被复制直到达到最小副本数</xhtml:p><xhtml:p/><xhtml:p><xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">hadoop dfsadmin -safemode enter</xhtml:span></xhtml:p><xhtml:p>hadoop fs -put xxxx ./in    #<xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">报错</xhtml:span>，说明文件系统处于安全模式</xhtml:p><xhtml:p>hadoop fs -rmr ./in #<xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">报错</xhtml:span></xhtml:p><xhtml:p><xhtml:span style-id="6tnvhc8mqcfbiot316h38fn622">hadoop dfsadmin -safemode leave</xhtml:span></xhtml:p><xhtml:p>hadoop fs -ls ./in</xhtml:p><xhtml:p/></html><plain>1、NameNode启动时会先经过一个“安全模式”阶段
2、安全模式阶段不会产生数据写入
3、在此阶段NameNode手机各个DataNode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的
4、在一定比例（可设置）的数据块被确定为“安全”后，在过若干时间，安全模式结束
5、当检测到副本数不足的数据块时，该块会被复制直到达到最小副本数

hadoop dfsadmin -safemode enter
hadoop fs -put xxxx ./in    #报错，说明文件系统处于安全模式
hadoop fs -rmr ./in #报错
hadoop dfsadmin -safemode leave
hadoop fs -ls ./in
</plain></notes></topic><topic id="4ija0be6mbg7annatclplk01sj" timestamp="1394163240115"><title>5、校验和</title><notes><html><xhtml:p>1、在文件创立时，每个数据块都产生校验和</xhtml:p><xhtml:p>2、校验和保存在.meta文件内，crc校验</xhtml:p><xhtml:p>3、客户端读取数据时可以检查校验和是否相同，从而发现数据块是否损坏</xhtml:p><xhtml:p>4、如果正在读取的数据块损坏，则可以继续读取其他副本</xhtml:p><xhtml:p/><xhtml:p><xhtml:img xhtml:src="xap:attachments/406gvhchgau20ke625kqkc0vkb.png"/></xhtml:p></html><plain>1、在文件创立时，每个数据块都产生校验和
2、校验和保存在.meta文件内，crc校验
3、客户端读取数据时可以检查校验和是否相同，从而发现数据块是否损坏
4、如果正在读取的数据块损坏，则可以继续读取其他副本

</plain></notes></topic><topic id="1993ikkgnjo6kd7bieivrdtfj5" timestamp="1394163715263"><title>6、回收站</title><notes><html><xhtml:p>1、删除文件时，其实是放入回收站/trash</xhtml:p><xhtml:p>2、回收站里的文件可以快速恢复</xhtml:p><xhtml:p>3、可以设置一个时间阈值，当回收站里文件的存放时间超过这个阈值，就被彻底删除，并且释放占用的数据块</xhtml:p><xhtml:p/><xhtml:p>hadoop fs -put xxxx ./in/test1.txt</xhtml:p><xhtml:p>hadoop fs -rmr ./in/test1.txt #move to trash</xhtml:p><xhtml:p>生成~/.Trash目录</xhtml:p><xhtml:p>~/.Trash/Current/user/wanglj/in/test1.txt</xhtml:p><xhtml:p/><xhtml:p>hadoop fs -mv ./.Trash/Current/user/wanglj/in/test1.txt ./in</xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/6ppru6voacttjtaee5pefm6c9d.png"/></xhtml:p></html><plain>1、删除文件时，其实是放入回收站/trash
2、回收站里的文件可以快速恢复
3、可以设置一个时间阈值，当回收站里文件的存放时间超过这个阈值，就被彻底删除，并且释放占用的数据块

hadoop fs -put xxxx ./in/test1.txt
hadoop fs -rmr ./in/test1.txt #move to trash
生成~/.Trash目录
~/.Trash/Current/user/wanglj/in/test1.txt

hadoop fs -mv ./.Trash/Current/user/wanglj/in/test1.txt ./in
</plain></notes></topic><topic id="5ffpruh3lge1prp1g3dp9q4til" timestamp="1394163855823"><title>7、元数据保护</title><notes><html><xhtml:p>1、映像文件和事务日志是NameNode的核心数据。可以配置为拥有多个副本</xhtml:p><xhtml:p>2、副本会降低NameNode的处理速度，但增加安全性</xhtml:p><xhtml:p>3、NameNode依然是单点，如果发生故障要手工切换</xhtml:p><xhtml:p/><xhtml:p/><xhtml:p><xhtml:img xhtml:src="xap:attachments/7s4lko42dsg396cigaic74k18c.png"/></xhtml:p></html><plain>1、映像文件和事务日志是NameNode的核心数据。可以配置为拥有多个副本
2、副本会降低NameNode的处理速度，但增加安全性
3、NameNode依然是单点，如果发生故障要手工切换


</plain></notes></topic><topic id="2790prg61njdgdo7kb7e00c5hi" timestamp="1394163988864"><title>8、快照机制</title><notes><html><xhtml:p>1、支持存储某个时间点的映像，需要时可以使数据重返这个时间点的状态</xhtml:p><xhtml:p>2、hadoop目前还不支持快照，已经列入开发计划，传说在hadoop2.x某版本里将获得此功能</xhtml:p><xhtml:p>https://issues.apache.org/jira/browse/HDFS-2802</xhtml:p><xhtml:p/></html><plain>1、支持存储某个时间点的映像，需要时可以使数据重返这个时间点的状态
2、hadoop目前还不支持快照，已经列入开发计划，传说在hadoop2.x某版本里将获得此功能
https://issues.apache.org/jira/browse/HDFS-2802
</plain></notes></topic></topics></children></topic></topics></children></topic><topic id="24k921geccrqhoma0jgquvvdjn" timestamp="1394161571376"><title>数据读写流程</title><children><topics type="attached"><topic id="6qgtvboqnck1kr8qe7ihhc1ec8" timestamp="1394161571363"><title>读取数据流程</title><notes><html><xhtml:p>1、客户端要访问HDFS中的一个文件</xhtml:p><xhtml:p>2、首先从namenode获得组成这个文件的数据块位置列表</xhtml:p><xhtml:p>3、根据列表知道存储数据块的datanode</xhtml:p><xhtml:p>4、访问datanode获取数据</xhtml:p><xhtml:p>5、namenode并不参与数据实际传输</xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/7g15d6dfe1iduqvdtu8mltuhqi.png"/></xhtml:p></html><plain>1、客户端要访问HDFS中的一个文件
2、首先从namenode获得组成这个文件的数据块位置列表
3、根据列表知道存储数据块的datanode
4、访问datanode获取数据
5、namenode并不参与数据实际传输
</plain></notes></topic><topic id="6c7fe5l2fjpa284n1161d44dh8" timestamp="1394161571363"><title>文件写入</title><notes><html><xhtml:p>1、客户端请求namenode创建新文件</xhtml:p><xhtml:p>2、客户端将数据写入DFSOutputStream</xhtml:p><xhtml:p>3、建立pipeline依次将目标数据块写入各个datanode，建立多个副本</xhtml:p><xhtml:p/><xhtml:p><xhtml:img xhtml:src="xap:attachments/3ie18gd8kjbb953a6i0lpvefam.png"/></xhtml:p></html><plain>1、客户端请求namenode创建新文件
2、客户端将数据写入DFSOutputStream
3、建立pipeline依次将目标数据块写入各个datanode，建立多个副本

</plain></notes></topic></topics></children></topic><topic id="7knh135altimlasko6s2h7qt3i" timestamp="1394164024127"><title>hdfs文件操作</title></topic></topics></children></topic><topic branch="folded" id="2hno0ig96rkim61t23rbjf0dai" timestamp="1394439137081"><title>3、hadoop shell</title><children><topics type="attached"><topic id="0f7c19fod8u5oipa1pue9uo033" timestamp="1394095299068"><title>shell命令</title><children><topics type="attached"><topic id="2nl1lreqicvpnmeio4dmhaobma" timestamp="1394095297527"><title>1、创建目录</title><notes><html><xhtml:p>hadoop fs -mkdir /tmp/input</xhtml:p></html><plain>hadoop fs -mkdir /tmp/input</plain></notes></topic><topic id="6sp3553sfla7l1v5bu8hmo44o6" timestamp="1394095561410"><title>2、拷贝文件</title><notes><html><xhtml:p>#put拷贝local文件到hdfs</xhtml:p><xhtml:p>hadoop fs -put input/* /tmp/input/</xhtml:p><xhtml:p>#</xhtml:p><xhtml:p>hadoop fs -cp tmp tmp2</xhtml:p></html><plain>#put拷贝local文件到hdfs
hadoop fs -put input/* /tmp/input/
#
hadoop fs -cp tmp tmp2</plain></notes></topic><topic id="675vm2sfpjb2d8hspkom6o2r9p" timestamp="1394090876477"><title>3、执行jar</title><notes><html><xhtml:p>hadoop jar hadoop-example.jar wordcount /tmp/input /tmp/output</xhtml:p><xhtml:p/><xhtml:p>hadoop fs -cat /tmp/output</xhtml:p><xhtml:p/><xhtml:p/></html><plain>hadoop jar hadoop-example.jar wordcount /tmp/input /tmp/output

hadoop fs -cat /tmp/output

</plain></notes></topic><topic id="77140sf15g8ttauvhoqs0er0eo" timestamp="1394096152748"><title>4、ls lsr</title><notes><html><xhtml:p>hadoop fs -help mv</xhtml:p><xhtml:p/><xhtml:p>hadoop fs -ls /tmp/input</xhtml:p><xhtml:p/><xhtml:p>#递归显示</xhtml:p><xhtml:p>hadoop fs -lsr /tmp/input</xhtml:p><xhtml:p>#显示文件大小</xhtml:p><xhtml:p>hadoop fs -du /tmp</xhtml:p><xhtml:p>#显示整个文件的大小</xhtml:p><xhtml:p>hadoop fs -dus /tmp</xhtml:p><xhtml:p>#</xhtml:p><xhtml:p>hadoop fs -count /tmp</xhtml:p><xhtml:p>hadoop fs -copyFromLocal file1 /tmp</xhtml:p><xhtml:p>hadoop fs -moveFromLocal file2 /tmp</xhtml:p><xhtml:p/></html><plain>hadoop fs -help mv

hadoop fs -ls /tmp/input

#递归显示
hadoop fs -lsr /tmp/input
#显示文件大小
hadoop fs -du /tmp
#显示整个文件的大小
hadoop fs -dus /tmp
#
hadoop fs -count /tmp
hadoop fs -copyFromLocal file1 /tmp
hadoop fs -moveFromLocal file2 /tmp
</plain></notes></topic></topics></children></topic><topic id="0an8s76d0sgj2ec7ef4kj0qhbg" timestamp="1394091754382"><title>hadoop bin目录下命令</title><children><topics type="attached"><topic id="491hthcficv026vdr6hp6q59t1" timestamp="1394093074134"><title>hadoop</title><notes><html><xhtml:p>start-dfs.sh -&gt; hadoop-daemon.sh -&gt; hadoop</xhtml:p><xhtml:p/><xhtml:p>hadoop fsch /</xhtml:p><xhtml:p/><xhtml:p>hadoop distcp "hdfs://localhost:9000/tmp/test" "hdfs://localhost:9000/tmp/test2"</xhtml:p><xhtml:p/><xhtml:p>hadoop daemonlog -getlevel 127.0.0.1:50070 namenode</xhtml:p><xhtml:p>hadoop daemonlog -setlevel 127.0.0.1:50070 namenode info</xhtml:p></html><plain>start-dfs.sh -&gt; hadoop-daemon.sh -&gt; hadoop

hadoop fsch /

hadoop distcp "hdfs://localhost:9000/tmp/test" "hdfs://localhost:9000/tmp/test2"

hadoop daemonlog -getlevel 127.0.0.1:50070 namenode
hadoop daemonlog -setlevel 127.0.0.1:50070 namenode info</plain></notes></topic><topic id="72qeki91kc9ra3u4h1fvvboe0l" timestamp="1394091085703"><title>hadoop-config.sh</title><notes><html><xhtml:p>对一些变量进行赋值</xhtml:p><xhtml:p/></html><plain>对一些变量进行赋值
</plain></notes></topic><topic id="7bh1anb2obr9fktchh1lcptidv" timestamp="1394091885629"><title>hadoop-daemon.sh</title><notes><html><xhtml:p>启动单个节点</xhtml:p><xhtml:p/><xhtml:p>hadoop-daemon.sh start/stop namenode</xhtml:p><xhtml:p/><xhtml:p>hadoop-daemon.sh start/stop datanode</xhtml:p><xhtml:p/><xhtml:p>hadoop-daemon.sh start/stop tasktracker</xhtml:p><xhtml:p/><xhtml:p/></html><plain>启动单个节点

hadoop-daemon.sh start/stop namenode

hadoop-daemon.sh start/stop datanode

hadoop-daemon.sh start/stop tasktracker

</plain></notes></topic><topic id="4l0givtfmi4tonvbua6mgagkct" timestamp="1394094791187"><title>hadoop-daemons.sh</title><notes><html><xhtml:p>在所有slaves上运行相同的脚本hadoop-daemon.sh</xhtml:p><xhtml:p/></html><plain>在所有slaves上运行相同的脚本hadoop-daemon.sh
</plain></notes></topic><topic id="503jmb2rguo0evp7biccnfuqhd" timestamp="1394091628535"><title>start-all.sh</title></topic><topic id="6ddh9iq16ccg5dus9of5ko368k" timestamp="1394091762978"><title>start-dfs.sh</title></topic><topic id="75qkg1v6r0co5ca6gf3mbcuoti" timestamp="1394091776305"><title>start-mapred.sh</title></topic><topic id="0i84jslkl9kvp6o7p3p29jm2fv" timestamp="1394091718193"><title>start-balancer.sh</title><notes><html><xhtml:p>用于负载均衡</xhtml:p></html><plain>用于负载均衡</plain></notes></topic><topic id="3os1d176tsodt4pc66tefo2ada" timestamp="1394091734646"><title>start-jobhistoryserver.sh</title></topic></topics></children></topic></topics></children><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/3ci8r6mtovcp7nojgojmj0k5eu.png"/></xhtml:p></html><plain/></notes></topic><topic branch="folded" id="78h9uu2h418ab55dan5ocpbm0b" timestamp="1394439104983"><title>2、分布式安装</title><children><topics type="attached"><topic id="4vj9v71i1jn8odpbaqbon1lh2m" timestamp="1394087663565"><title>1、windows</title><children><topics type="attached"><topic id="5j9ffqbdj0bg2j909pk3co6urd" timestamp="1394085860880"><title>1、jdk</title></topic><topic id="7pqhoo2r61embd05spsc12b79t" timestamp="1394086235210"><title>2、cygwin linux虚拟平台</title><notes><html><xhtml:p>http://www.cygwin.com/</xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/609tkcnvi0o2kjt2hk3rhgsblb.png"/></xhtml:p></html><plain>http://www.cygwin.com/
</plain></notes></topic><topic id="27lam1cf7atbnn693tgd1gqib5" timestamp="1394106368797"><title>3、安装ssh</title><notes><html><xhtml:p>#在cygwin下安装sshd服务</xhtml:p><xhtml:p>ssh-host-config</xhtml:p><xhtml:p/><xhtml:p>#启动sshd服务</xhtml:p><xhtml:p>net start sshd</xhtml:p><xhtml:p/><xhtml:p>ssh-keygen -t rsa</xhtml:p><xhtml:p/><xhtml:p>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</xhtml:p><xhtml:p/></html><plain>#在cygwin下安装sshd服务
ssh-host-config

#启动sshd服务
net start sshd

ssh-keygen -t rsa

cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
</plain></notes></topic></topics></children></topic><topic id="0nk31t2ds7ck0hb4gr0hq33tvn" timestamp="1394158200881"><title>2、linux</title><children><topics type="attached"><topic id="2egdbchgnrpk5cd3les91ggvib" timestamp="1394088283394"><title>1、jdk</title></topic><topic id="5epes924vb5k1q71ad1j94pj3d" timestamp="1394158180787"><title>2、安装ssh</title><notes><html><xhtml:p>#启动sshd服务</xhtml:p><xhtml:p>service sshd start</xhtml:p><xhtml:p/><xhtml:p>ssh-keygen -t rsa</xhtml:p><xhtml:p/><xhtml:p>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</xhtml:p><xhtml:p/></html><plain>#启动sshd服务
service sshd start

ssh-keygen -t rsa

cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
</plain></notes></topic><topic id="2tpa52qg98hfs2dluhdunh42ul" timestamp="1394158204489"><title>3、关闭防火墙</title></topic></topics></children></topic><topic id="132gsksr9pak30eisalbm90hk7" timestamp="1394168348044"><title>3、hadoop安装</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/2dnbhppv13j1km4u9mulde4off.png"/></xhtml:p><xhtml:p><xhtml:span style-id="7turfdg0su2teous0bsv0h1b05"/></xhtml:p><xhtml:p><xhtml:span style-id="7turfdg0su2teous0bsv0h1b05">export HADOOP_HOME=/home/test/hadoop-1.0.0</xhtml:span></xhtml:p><xhtml:p><xhtml:span style-id="7turfdg0su2teous0bsv0h1b05"/></xhtml:p><xhtml:p><xhtml:img xhtml:src="xap:attachments/0tc9ciatenajb17ndct3hviahj.png"/></xhtml:p></html><plain>

export HADOOP_HOME=/home/test/hadoop-1.0.0

</plain></notes><children><topics type="attached"><topic id="5g0bdml6ghef66qnh6vqed5bes" timestamp="1394106567569"><title>1、conf/hadoop-env.sh</title><notes><html><xhtml:p>配置jdk</xhtml:p><xhtml:p>export JAVA_HOME=/cygdrive/d/java/jdk1.6</xhtml:p><xhtml:p/></html><plain>配置jdk
export JAVA_HOME=/cygdrive/d/java/jdk1.6
</plain></notes></topic><topic id="56n36a7q0cndm22ksc96sigkam" timestamp="1394154928709"><title>2、conf/core-site.xml</title><notes><html><xhtml:p>&lt;configuration&gt;</xhtml:p><xhtml:p>	&lt;property&gt;</xhtml:p><xhtml:p>		&lt;name&gt;fs.default.name&lt;/name&gt;</xhtml:p><xhtml:p>		&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</xhtml:p><xhtml:p>	&lt;/property&gt;</xhtml:p><xhtml:p/><xhtml:p>	&lt;!-- 默认情况下生产的tmp目录会存在hdfs中，系统重启会清除此目录内容 --&gt;</xhtml:p><xhtml:p>	&lt;property&gt;</xhtml:p><xhtml:p>		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</xhtml:p><xhtml:p>		&lt;value&gt;/home/wanglj/hadoop/tmp&lt;/value&gt;</xhtml:p><xhtml:p>	&lt;/property&gt;</xhtml:p><xhtml:p>&lt;/configuration&gt;</xhtml:p></html><plain>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.default.name&lt;/name&gt;
		&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
	&lt;/property&gt;

	&lt;!-- 默认情况下生产的tmp目录会存在hdfs中，系统重启会清除此目录内容 --&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;/home/wanglj/hadoop/tmp&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</plain></notes></topic><topic id="185rme2j39dhl859pk9eeh3a0g" timestamp="1394087449160"><title>3、conf/hdfs-site.xml</title><notes><html><xhtml:p>&lt;configuration&gt;</xhtml:p><xhtml:p>	&lt;property&gt;</xhtml:p><xhtml:p>		&lt;name&gt;dfs.replication&lt;/name&gt;</xhtml:p><xhtml:p>		&lt;value&gt;1&lt;/value&gt;</xhtml:p><xhtml:p>	&lt;/property&gt;</xhtml:p><xhtml:p>&lt;/configuration&gt;</xhtml:p></html><plain>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;1&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</plain></notes></topic><topic id="5ush1g9357taj987ehc2g3sf44" timestamp="1394087498724"><title>4、conf/mapred-site.xml</title><notes><html><xhtml:p>&lt;configuration&gt;</xhtml:p><xhtml:p>	&lt;property&gt;</xhtml:p><xhtml:p>		&lt;name&gt;mapred.job.tracker&lt;/name&gt;</xhtml:p><xhtml:p>		&lt;value&gt;localhost:9001&lt;/value&gt;</xhtml:p><xhtml:p>	&lt;/property&gt;</xhtml:p><xhtml:p>&lt;/configuration&gt;</xhtml:p></html><plain>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;mapred.job.tracker&lt;/name&gt;
		&lt;value&gt;localhost:9001&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</plain></notes></topic><topic id="6f86olp0g79a7u53j9e8t05emu" timestamp="1394162392966"><title>5、单点伪分布式配置</title><notes><html><xhtml:p>conf/masters和conf/slaves文件中默认设置均为localhost</xhtml:p><xhtml:p/><xhtml:p>其中conf/masters中的内容为SecondaryNameNode主机名</xhtml:p><xhtml:p>	conf/slaves中的内容为datanode主机名</xhtml:p><xhtml:p/></html><plain>conf/masters和conf/slaves文件中默认设置均为localhost

其中conf/masters中的内容为SecondaryNameNode主机名
	conf/slaves中的内容为datanode主机名
</plain></notes></topic><topic id="3koi406o1vcei7heka5gmv6l49" timestamp="1394168387312"><title>6、其他</title><notes><html><xhtml:p>conf/hadoop-env.sh</xhtml:p><xhtml:p/><xhtml:p>export HAOOP_CLASSPATH=/home/wanglj/hadoop-1.2.1/myclass</xhtml:p><xhtml:p/></html><plain>conf/hadoop-env.sh

export HAOOP_CLASSPATH=/home/wanglj/hadoop-1.2.1/myclass
</plain></notes></topic></topics></children></topic><topic id="7tamn2299kqgnajhnfptc3rkg4" timestamp="1394167404571"><title>4、启动hadoop</title><notes><html><xhtml:p>1、格式化文件系统</xhtml:p><xhtml:p>	hadoop namenode -format</xhtml:p><xhtml:p/><xhtml:p>2、启动hadoop</xhtml:p><xhtml:p>	启动关闭所有任务 start-all.sh/stop-all.sh</xhtml:p><xhtml:p>	启动关闭HDFS start-dfs.sh/stop-dfs.sh</xhtml:p><xhtml:p>	启动关闭MapReduce start-mapred.sh/stop-mapred.sh</xhtml:p><xhtml:p/><xhtml:p>3、用jps命令查看进程，确保有</xhtml:p><xhtml:p>	NameNode， DataNode， JobTracker， TaskTracker</xhtml:p><xhtml:p/></html><plain>1、格式化文件系统
	hadoop namenode -format

2、启动hadoop
	启动关闭所有任务 start-all.sh/stop-all.sh
	启动关闭HDFS start-dfs.sh/stop-dfs.sh
	启动关闭MapReduce start-mapred.sh/stop-mapred.sh

3、用jps命令查看进程，确保有
	NameNode， DataNode， JobTracker， TaskTracker
</plain></notes><children><topics type="attached"><topic id="5rj3hhjk9cbl8dvm9m8ga93fqa" timestamp="1394167456593"><title>添加节点</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/2ivua4js0ount0aq9nciftinhd.png"/></xhtml:p></html><plain/></notes></topic></topics></children></topic><topic id="34fmcfb4u9879e0ir9a3c6ch7s" timestamp="1394089731640"><title>5、Hadoop ui</title><notes><html><xhtml:p>		http://localhost:50070/		查看HDFS管理页面</xhtml:p><xhtml:p>		http://localhost:50030/		查看JobTracker管理页面</xhtml:p><xhtml:p>		HDFS通信端口：9000</xhtml:p><xhtml:p>		MapReduce通信端口：9001</xhtml:p><xhtml:p/></html><plain>		http://localhost:50070/		查看HDFS管理页面
		http://localhost:50030/		查看JobTracker管理页面
		HDFS通信端口：9000
		MapReduce通信端口：9001
</plain></notes></topic><topic id="6p4q8okoart1k74e5gbinlj5ne" timestamp="1394106873545"><title>6、eclipse集成开发环境</title><notes><html><xhtml:p>1、导入hadoop-core.jar 以及 hadoop/lib下的所有jar包</xhtml:p><xhtml:p>2、加入hadoop配置文件，包括conf/core-site.xml,conf/hdfs-site.xml,conf/mapred-site.xml，并修改相应参数</xhtml:p><xhtml:p/></html><plain>1、导入hadoop-core.jar 以及 hadoop/lib下的所有jar包
2、加入hadoop配置文件，包括conf/core-site.xml,conf/hdfs-site.xml,conf/mapred-site.xml，并修改相应参数
</plain></notes></topic></topics></children></topic><topic branch="folded" id="5ghis7pqe2k36irsplulj546ql" timestamp="1394439097306"><title>1、Hadoop简介</title><notes><html><xhtml:p>1、hadoop是一个开源，可以更容易开发和处理大数据的软件平台，它包括两部分：</xhtml:p><xhtml:p>	a、HDFS</xhtml:p><xhtml:p>	b、MapReduce</xhtml:p><xhtml:p>	提供的是云平台基础架构</xhtml:p><xhtml:p>	1.0</xhtml:p><xhtml:p>	开发分布式程序：</xhtml:p><xhtml:p/><xhtml:p>2、它是依据google的论文gfs，MapReduce模型 bigtable</xhtml:p><xhtml:p>									hadoop MapReduce HDFS</xhtml:p><xhtml:p/><xhtml:p>3、优点：</xhtml:p><xhtml:p>	可扩展、经济、可靠、高效</xhtml:p><xhtml:p/><xhtml:p>4、Pig 有一套原语，使用户不用写MapReduce程序</xhtml:p><xhtml:p>	 Hive 是一个数据仓库，提供类SQL，映射成表</xhtml:p><xhtml:p>	 HBase 是一个分布式数据库</xhtml:p><xhtml:p>	 ZooKeeper 是一个分布式的协调框架</xhtml:p><xhtml:p/><xhtml:p>5、hadoop hdfs 是一个分布式的文件系统</xhtml:p><xhtml:p>	特点：	高容错性</xhtml:p><xhtml:p>				可以部署在廉价的硬件上</xhtml:p><xhtml:p>				高吞吐量</xhtml:p><xhtml:p/><xhtml:p>6、hadoop mapreduce</xhtml:p><xhtml:p>	是将map reduce 进行自动的并行化分配，达到一定的计算能力</xhtml:p><xhtml:p/><xhtml:p>7、学习资源</xhtml:p><xhtml:p>	Hadoop的官网 http://hadoop.apache.org</xhtml:p><xhtml:p>	Cloudera的官网 http://www.cloudera.com/content/cloudera/en/home.html</xhtml:p></html><plain>1、hadoop是一个开源，可以更容易开发和处理大数据的软件平台，它包括两部分：
	a、HDFS
	b、MapReduce
	提供的是云平台基础架构
	1.0
	开发分布式程序：

2、它是依据google的论文gfs，MapReduce模型 bigtable
									hadoop MapReduce HDFS

3、优点：
	可扩展、经济、可靠、高效

4、Pig 有一套原语，使用户不用写MapReduce程序
	 Hive 是一个数据仓库，提供类SQL，映射成表
	 HBase 是一个分布式数据库
	 ZooKeeper 是一个分布式的协调框架

5、hadoop hdfs 是一个分布式的文件系统
	特点：	高容错性
				可以部署在廉价的硬件上
				高吞吐量

6、hadoop mapreduce
	是将map reduce 进行自动的并行化分配，达到一定的计算能力

7、学习资源
	Hadoop的官网 http://hadoop.apache.org
	Cloudera的官网 http://www.cloudera.com/content/cloudera/en/home.html</plain></notes><children><topics type="attached"><topic id="6olf7p9t77dsg99k8vp2qo2p96" timestamp="1394158596093"><title>1、hadoop特性</title><notes><html><xhtml:p>Append：支持文件追加功能，如果想使用HBase，OLTP（联机事务），需要这个特性</xhtml:p><xhtml:p>RAID：在保证数据可靠的前提下，通过引入校验码减少数据块数目。详细链接：https://issues.apache.org/jira/browse/HDFS/component/12313080</xhtml:p><xhtml:p>Symlink:支持HDFS文件链接，具体可参考：https://issues.apache.org/jira/browse/HDFS-245</xhtml:p><xhtml:p>Security:Hadoop安全性，具体可参考：https://issues.apache.org/jira/browse/HADOOP-4487</xhtml:p><xhtml:p>NameNode HA（high avaible），可以可参考：https://issues.apache.org/jira/browse/HDFS-1064 </xhtml:p><xhtml:p>HDFS Federation和YARN</xhtml:p><xhtml:p/></html><plain>Append：支持文件追加功能，如果想使用HBase，OLTP（联机事务），需要这个特性
RAID：在保证数据可靠的前提下，通过引入校验码减少数据块数目。详细链接：https://issues.apache.org/jira/browse/HDFS/component/12313080
Symlink:支持HDFS文件链接，具体可参考：https://issues.apache.org/jira/browse/HDFS-245
Security:Hadoop安全性，具体可参考：https://issues.apache.org/jira/browse/HADOOP-4487
NameNode HA（high avaible），可以可参考：https://issues.apache.org/jira/browse/HDFS-1064 
HDFS Federation和YARN
</plain></notes></topic><topic id="5v2oefvc99mt74oj4lptgjb2op" timestamp="1394158591747"><title>2、版本演进</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/1jagatit3igqpovnrdsbd4560l.png"/></xhtml:p></html><plain/></notes></topic><topic id="0v30rqkosarvk3bu13tuot2met" timestamp="1394158990742"><title>3、Cloudera发布版</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/75jlqplsj8bphuccrbl1s6reg5.png"/></xhtml:p></html><plain/></notes></topic><topic id="4lav1561fvnt4gk12asub8g6lq" timestamp="1394169669956"><title>4、book</title><notes><html><xhtml:p><xhtml:img xhtml:src="xap:attachments/3021nek47h8tiprri9u1us6n9c.png"/></xhtml:p></html><plain/></notes></topic></topics></children></topic></topics></children></topic><title>画布 1</title></sheet></xmap-content>